**Taller 1: Fundamentos y calibraci√≥n de c√°mara**  
**Visi√≥n por Computador**  
**Universidad Nacional de Colombia**  
**Docente:** Juan David Ospina Arango  
**Estudiantes:** 

* Santiago Betancur Montoya  
* Reinaldo David Lopez Narvaez  
* Jose Sebastian Garzon Parra  
* Monica Paola Vargas Tirado

**Introducci√≥n**

El procesamiento digital de im√°genes constituye uno de los pilares fundamentales de la visi√≥n por computador, al permitir la interpretaci√≥n autom√°tica de informaci√≥n visual mediante algoritmos matem√°ticos. En este primer taller se exploran los conceptos esenciales de calibraci√≥n de c√°mara, transformaciones de intensidad y geom√©tricas, ecualizaci√≥n de histogramas y segmentaci√≥n por color, con el prop√≥sito de comprender y manipular digitalmente la informaci√≥n contenida en las im√°genes.

El ejercicio se desarrolla de manera pr√°ctica utilizando fotograf√≠as capturadas con un tel√©fono celular, lo que permite simular un entorno real de adquisici√≥n de datos. A partir de dichas im√°genes, se aplican t√©cnicas b√°sicas de preprocesamiento y an√°lisis que permiten corregir distorsiones √≥pticas, modificar el brillo, contraste y niveles de iluminaci√≥n, realizar transformaciones espaciales, mejorar la distribuci√≥n tonal mediante ecualizaci√≥n y finalmente segmentar regiones de inter√©s con base en sus caracter√≠sticas crom√°ticas.

Estas actividades permiten no solo afianzar los fundamentos te√≥ricos del procesamiento de im√°genes, sino tambi√©n evidenciar c√≥mo cada operaci√≥n afecta la percepci√≥n visual y la informaci√≥n contenida en los p√≠xeles. De esta forma, el taller integra conceptos de geometr√≠a, estad√≠stica e interpretaci√≥n visual para construir una comprensi√≥n s√≥lida del flujo de trabajo que precede a tareas m√°s avanzadas de visi√≥n artificial, como la detecci√≥n de objetos, clasificaci√≥n o reconocimiento de patrones.

**Marco te√≥rico**

- **Distorsi√≥n de lente (barril/coj√≠n):**

La distorsi√≥n de lente es una aberraci√≥n √≥ptica que provoca que las l√≠neas rectas en una escena aparezcan curvadas en la imagen capturada. Este efecto se debe a la geometr√≠a y a la forma en que la lente proyecta la luz sobre el sensor de la c√°mara. Existen principalmente dos tipos de distorsi√≥n: la distorsi√≥n de barril, donde las l√≠neas rectas se curvan hacia afuera desde el centro de la imagen, com√∫n en lentes gran angulares; y la distorsi√≥n de coj√≠n, donde las l√≠neas se curvan hacia adentro, t√≠pica en lentes teleobjetivos. Matem√°ticamente, estas distorsiones pueden modelarse mediante funciones polinomiales que dependen de la distancia radial al centro √≥ptico. Corregir este tipo de errores requiere aplicar una transformaci√≥n inversa basada en los par√°metros intr√≠nsecos de la c√°mara, lo cual permite obtener una imagen rectificada que se aproxima a la proyecci√≥n ideal

- **Calibraci√≥n de c√°mara:** 

El proceso de calibraci√≥n de c√°mara se basa en estimar los par√°metros intr√≠nsecos (como la longitud focal, el centro √≥ptico y los coeficientes de distorsi√≥n radial y tangencial) y los par√°metros extr√≠nsecos (rotaci√≥n y traslaci√≥n del sistema de c√°mara respecto al mundo) para establecer una relaci√≥n precisa entre un punto 3D del mundo y su proyecci√≥n 2D en la imagen capturada (Sadekar & Mallick, 2020).  
Para obtener estos par√°metros se capturan m√∫ltiples vistas de un patr√≥n calibrado (frecuentemente un tablero de ajedrez), se localizan sus esquinas en la imagen, se asocian con las coordenadas del mundo definidas y se aplica un algoritmo como OpenCV `calibrateCamera()` para calcular la matriz intr√≠nseca, los coeficientes de distorsi√≥n, y los vectores de rotaci√≥n y traslaci√≥n. Este procedimiento permite corregir distorsiones y mejorar mediciones basadas en imagen para aplicaciones como rob√≥tica, visi√≥n por computador y autom√≥viles aut√≥nomos (GeeksforGeeks, 2025).

- **Tranformciones Geometricas:** Las transformaciones geom√©tricas sobre im√°genes permiten modificar su posici√≥n, orientaci√≥n o tama√±o sin alterar su contenido visual (al trabajar sobre la intensidad de cada pixel). Para representar estas transformaciones de manera uniforme y eficiente, se emplean las coordenadas homog√©neas, que a√±aden una dimensi√≥n extra al sistema de coordenadas tradicional. Esto facilita expresar traslaciones, rotaciones y escalados mediante una √∫nica matriz homog√©nea, la cual combina todas estas operaciones en una misma formulaci√≥n matem√°tica. De esta forma, las transformaciones pueden aplicarse mediante multiplicaciones matriciales, simplificando el procesamiento y la composici√≥n de m√∫ltiples cambios geom√©tricos sobre la imagen.  
- **Transformaciones de intensidad a nivel de pixel:** El procesamiento digital de im√°genes se fundamenta en la aplicaci√≥n de transformaciones puntuales que modifican las propiedades visuales de una imagen a nivel de p√≠xel. Entre las m√°s comunes se encuentran el ajuste de brillo, que incrementa o reduce la luminosidad global al sumar o restar un valor constante; el ajuste de contraste, que ampl√≠a o comprime el rango tonal para acentuar o suavizar las diferencias entre zonas claras y oscuras; y la correcci√≥n gamma, una operaci√≥n no lineal que compensa las caracter√≠sticas de visualizaci√≥n de los dispositivos y la percepci√≥n humana, equilibrando el brillo y el contraste de forma m√°s natural. Estas transformaciones son esenciales para optimizar la visualizaci√≥n y mejorar la calidad perceptual de las im√°genes digitales (L√≥pez, 2012).

Asimismo, el tratamiento de im√°genes puede incluir operaciones aritm√©ticas como suma, resta, multiplicaci√≥n y divisi√≥n entre im√°genes o con constantes. Estas permiten realizar tareas de realce, fusi√≥n o comparaci√≥n visual, destacando diferencias o atenuando regiones espec√≠ficas. Por ejemplo, la suma puede aumentar el brillo o combinar dos im√°genes, la resta resalta variaciones entre ellas, la multiplicaci√≥n se emplea para aplicar m√°scaras o modificar la iluminaci√≥n, y la divisi√≥n sirve para detectar cambios o corregir irregularidades de luz. En conjunto, estas transformaciones constituyen la base del an√°lisis y procesamiento visual en m√∫ltiples aplicaciones de la visi√≥n por computador y la ingenier√≠a digital (Soluci√≥n Ingenieril, s. f.). 

- **Ecualizaci√≥n de histogramas:** La ecualizaci√≥n de histograma es una t√©cnica de mejora del contraste que busca redistribuir los niveles de intensidad de una imagen para utilizar de manera m√°s uniforme todo el rango din√°mico disponible.

Este proceso se basa en la funci√≥n de distribuci√≥n acumulada (CDF) del histograma original, que transforma los valores de intensidad r en nuevos valores s, dando como resultado una imagen con un contraste m√°s equilibrado y una mejor diferenciaci√≥n entre regiones claras y oscuras. Esta t√©cnica es especialmente √∫til en im√°genes con iluminaci√≥n desigual o bajo contraste, como fotograf√≠as nocturnas o subexpuestas, aunque puede incrementar el ruido en √°reas uniformes.

- **Segmentaci√≥n por color:** 

La segmentaci√≥n de im√°genes permite dividir una imagen en regiones que representan objetos o √°reas de inter√©s, facilitando su an√°lisis. En este caso, se utiliza para reconocer objetos de distintos colores, contarlos y calcular su tama√±o en p√≠xeles.

Para lograrlo, se emplean los espacios de color HSV y LAB, que ayudan a distinguir mejor los tonos y la iluminaci√≥n. Con el uso de m√°scaras y operaciones morfol√≥gicas, se a√≠sla la zona de inter√©s (como la mesa) y se eliminan ruidos del fondo. Finalmente, se obtienen los contornos y el √°rea de cada objeto, permitiendo una identificaci√≥n precisa y visualmente clara de los colores presentes en la escena.

**Metodolog√≠a**

1. **Calibraci√≥n de c√°maras**

Se imprime un patr√≥n calibrado (por ejemplo un tablero de ajedrez) y se toman m√∫ltiples im√°genes desde distintas orientaciones y distancias para abarcar diversas perspectivas del patr√≥n. Luego se detectan las esquinas del patr√≥n en cada imagen y se asocian estos puntos 2D con sus coordenadas espaciales 3D conocidas, tras lo cual se aplica la funci√≥n de calibraci√≥n (OpenCV `calibrateCamera()`) para estimar los par√°metros intr√≠nsecos (matriz de c√°mara) y de distorsi√≥n, as√≠ como los vectores de rotaci√≥n y traslaci√≥n, y finalmente se verifican los resultados undistorcionando nuevas im√°genes y comprobando el error de reproyecci√≥n.

2. **Transformaciones de intensidad a nivel de pixel**

Se definieron diversas funciones para realizar transformaciones sobre las im√°genes, entre ellas `ajuste_brillo()`, `ajuste_contraste()` y `correcci√≥n_gamma()`, junto con funciones auxiliares destinadas al manejo y normalizaci√≥n de las mismas. Posteriormente, se procedi√≥ a cargar las fotograf√≠as de la fachada tomadas a las 6:00 a.m. y a las 7:00 p.m., sobre las cuales se aplicaron las transformaciones mencionadas, con el prop√≥sito de analizar y visualizar los efectos de cada ajuste sobre la imagen original.

De manera complementaria, se implementaron funciones para realizar operaciones aritm√©ticas entre im√°genes, tales como `suma()`, `resta()`, `multiplicaci√≥n()` y `divisi√≥n()`. Estas operaciones se aplican igualmente a las im√°genes capturadas a las 6:00 a.m. y 7:00 p.m., con el fin de observar c√≥mo dichas combinaciones matem√°ticas afectan la composici√≥n visual y los valores de intensidad de los p√≠xeles, permitiendo una comprensi√≥n m√°s profunda de los principios de procesamiento digital de im√°genes.

3. **Transformaciones de rotaci√≥n y traslaci√≥n**

Iniciamos con la creaci√≥n de funciones que permiten construir matrices en coordenadas homog√©neas para las transformaciones de rotaci√≥n, escalamiento y traslaci√≥n, cada una definida seg√∫n los par√°metros espec√≠ficos que la determinan. Con estas funciones se desarrolla posteriormente una rutina que genera la matriz homog√©nea compuesta, la cual combina las transformaciones b√°sicas en una √∫nica representaci√≥n matricial, facilitando su aplicaci√≥n sobre im√°genes digitales.

A partir de esta composici√≥n, se generan m√∫ltiples matrices homog√©neas (por defecto, ocho) modificando los par√°metros de rotaci√≥n, escalamiento y traslaci√≥n para cada una. Estas matrices se aplican a una imagen previamente cargada, obteniendo un conjunto de resultados que se almacenan como frames. Posteriormente, los frames se integran para formar un GIF que muestra la secuencia de transformaciones. Todas las operaciones se realizaron tomando como referencia el centro de la imagen, por lo que la aplicaci√≥n de cada transformaci√≥n depende directamente de sus dimensiones. Adem√°s, se aplic√≥ un padding a cada frame con el fin de evitar la aparici√≥n de zonas negras alrededor de la imagen transformada.

4. **Distribuci√≥n de intensidades de una imagen**

Se cargaron dos im√°genes de la misma fachada tomadas en diferentes condiciones de iluminaci√≥n (6 AM y 7PM). Ambas fueron redimensionadas y convertidas a escala de grises para analizar √∫nicamente la distribuci√≥n de intensidades. Posteriormente, se aplic√≥ la ecualizaci√≥n de histograma utilizando la funci√≥n `cv.equalizeHist()` de OpenCV, con el fin de redistribuir los niveles de brillo y mejorar el contraste.

Finalmente, se calcularon y graficaron los histogramas y funciones de distribuci√≥n acumulada (CDF) antes y despu√©s del proceso para comparar los cambios en la representaci√≥n tonal entre la imagen diurna y la nocturna.

5. **Segmentaci√≥n de im√°genes**

Para esta actividad, nuestro grupo captur√≥ una imagen en una oficina con varios objetos de diferentes colores sobre una mesa, usando la c√°mara de un tel√©fono celular. Empleando las librer√≠as OpenCV y NumPy para el manejo de im√°genes y operaciones num√©ricas. La imagen fue cargada, redimensionada y convertida a los espacios de color HSV y LAB, lo que permiti√≥ trabajar con informaci√≥n de tono, saturaci√≥n y luminosidad de forma m√°s precisa que en el formato RGB.

El paso m√°s importante fue la creaci√≥n de m√°scaras, utilizadas para aislar la superficie de la mesa y excluir el fondo o las paredes. Estas m√°scaras se generaron mediante condiciones de brillo y saturaci√≥n, y luego se limpiaron con operaciones morfol√≥gicas de apertura y cierre para eliminar el ruido. La m√°scara final defini√≥ la regi√≥n de inter√©s, sobre la cual se realiz√≥ toda la segmentaci√≥n por color, evitando errores en zonas no relevantes.

Finalmente, se aplicaron rangos de color en el espacio HSV para detectar objetos azules, verdes, rojos, naranjas, blancos y grises. Con las m√°scaras de cada color se identificaron los contornos de los objetos, se filtraron por √°rea m√≠nima y se calcul√≥ su tama√±o en p√≠xeles. Los resultados se visualizaron en una imagen anotada que muestra los objetos detectados y sus √°reas, comprobando la efectividad del uso de las m√°scaras y las librer√≠as empleadas para la segmentaci√≥n.

**Resultados y An√°lisis**

1. **Calibraci√≥n de c√°maras**

Los resultados obtenidos del proceso de calibraci√≥n muestran una buena consistencia en los par√°metros intr√≠nsecos y una representaci√≥n fiel del comportamiento √≥ptico de la c√°mara. Se determin√≥ que la distorsi√≥n predominante es de tipo barril, lo cual se evidencia tanto en los valores positivos de los coeficientes radiales ùëò\_2 y ùëò\_3, como en la curvatura convexa de las l√≠neas rectas hacia los bordes de las im√°genes originales. Los valores de las longitudes focales ùëì\_ùë• \= 280.4 y ùëì\_ùë¶ \= 281.6 resultaron muy similares, indicando una correcta proporci√≥n entre los ejes del sensor y una calibraci√≥n precisa, sin deformaciones anis√≥tropas significativas. Asimismo, el punto principal (ùëê\_ùë•, ùëê\_ùë¶) \= (183.67, 164.88) se encuentra pr√≥ximo al centro de la imagen, lo que confirma una adecuada alineaci√≥n entre el eje √≥ptico y el sensor. En conjunto, estos resultados reflejan una calibraci√≥n estable y coherente, reforzada por un bajo error RMS de reproyecci√≥n (‚âà 0.27), que garantiza una correspondencia precisa entre los puntos proyectados y observados. La correcci√≥n aplicada elimin√≥ eficazmente la distorsi√≥n radial, obteniendo im√°genes rectificadas con l√≠neas bien alineadas, lo cual valida la calidad del modelo de c√°mara empleado.

2. **Transformaciones de intensidad a nivel de pixel**

La aplicaci√≥n de transformaciones de intensidad a nivel de p√≠xel permiti√≥ modificar de forma controlada las caracter√≠sticas visuales de las im√°genes seg√∫n las condiciones de iluminaci√≥n. En la imagen diurna, los ajustes de brillo y contraste evidenciaron que el aumento del brillo realza las zonas claras pero puede provocar p√©rdida de detalle por saturaci√≥n, mientras que un incremento del contraste mejora la definici√≥n de bordes y sombras al ampliar el rango tonal. Por su parte, la correcci√≥n gamma (Œ≥ \< 1\) permiti√≥ iluminar de manera m√°s uniforme sin saturar los valores altos de intensidad, siendo especialmente √∫til para compensar condiciones de baja iluminaci√≥n.

En la imagen nocturna, los mismos ajustes contribuyeron a resaltar detalles ocultos en las sombras, aunque un incremento excesivo del brillo introdujo cierto ruido visual. Las operaciones aritm√©ticas entre im√°genes (A y B) mostraron diferentes comportamientos: la suma (A \+ B) gener√≥ una fusi√≥n m√°s brillante que combina informaci√≥n de ambas tomas; la resta (|A ‚àí B|) resalt√≥ las diferencias de iluminaci√≥n y color entre el d√≠a y la noche; la multiplicaci√≥n (A √ó B) oscureci√≥ la escena, siendo √∫til para analizar regiones comunes; y la divisi√≥n (A / B) amplific√≥ las diferencias de luminancia, destacando las estructuras m√°s iluminadas. En conjunto, estos resultados demuestran que las transformaciones de intensidad son herramientas fundamentales en visi√≥n por computador, al mejorar la percepci√≥n visual, realizar correcciones fotom√©tricas y facilitar la segmentaci√≥n o detecci√≥n de caracter√≠sticas bajo condiciones de iluminaci√≥n variables.

3. **Transformaciones de rotaci√≥n y traslaci√≥n**

Al implementar y aplicar las transformaciones de rotaci√≥n y traslaci√≥n, se obtuvieron resultados visuales claros del efecto progresivo de cada operaci√≥n. El c√≥digo desarrollado permiti√≥ cargar una imagen base y generar entre ocho y doce transformaciones sucesivas, variando los par√°metros de rotaci√≥n, traslaci√≥n y escala en cada paso. Cada resultado intermedio se almacen√≥ como un frame, evidenciando los cambios graduales en la posici√≥n y orientaci√≥n de la imagen. Finalmente, la secuencia completa de frames se integr√≥ en un GIF animado que muestra de manera continua y din√°mica el proceso de transformaci√≥n. Este resultado permite observar c√≥mo la composici√≥n de transformaciones homog√©neas produce efectos coherentes y visualmente fluidos sobre la imagen original.

Adem√°s, para evitar la aparici√≥n de zonas negras en los bordes de la imagen durante las transformaciones, se implement√≥ un m√©todo de **padding** basado en el reflejo de los p√≠xeles del borde. Esta t√©cnica permiti√≥ extender el contenido de la imagen hacia las √°reas que quedaban vac√≠as tras las rotaciones o traslaciones, logrando que cada frame mantuviera una apariencia uniforme y continua. Gracias a este procedimiento, el GIF final presenta una transici√≥n m√°s limpia y sin interrupciones visuales en los l√≠mites de la imagen.

4. **Distribuci√≥n de intensidades de una imagen**

Tras aplicar la ecualizaci√≥n del histograma, se observ√≥ un incremento notable en el contraste general de ambas im√°genes, especialmente en la fotograf√≠a nocturna.  
 En la imagen diurna, la ecualizaci√≥n gener√≥ cambios leves al redistribuir los valores de intensidad, ya que la iluminaci√≥n original ya era uniforme. En contraste, la imagen nocturna present√≥ una ampliaci√≥n significativa del rango din√°mico, evidenciada en el histograma, que pas√≥ de estar concentrado en los niveles bajos a distribuirse de manera m√°s homog√©nea en todo el espectro de intensidades.

El resultado visual confirma que la ecualizaci√≥n mejora la visibilidad de detalles en escenas subexpuestas, permitiendo distinguir elementos que antes estaban ocultos por la baja iluminaci√≥n. Sin embargo, tambi√©n se aprecia un aumento del ruido en algunas zonas oscuras debido al realce de las diferencias de intensidad.

En conjunto, el an√°lisis demuestra que la ecualizaci√≥n del histograma es especialmente efectiva para mejorar el contraste en condiciones de iluminaci√≥n deficiente, aunque su efecto en im√°genes bien expuestas es m√°s limitado.

5. **Segmentaci√≥n de im√°genes**

El programa logr√≥ reconocer correctamente los objetos de distintos colores que aparecen en la imagen tomada en la oficina. En total se identificaron 15 objetos: 4 azules, 1 verde, 2 naranjas, 3 blancos, 3 grises y 2 rojos. A cada uno se le calcul√≥ su tama√±o en p√≠xeles, mostrando una buena relaci√≥n con su tama√±o real en la foto. En la imagen final se pueden ver los contornos bien marcados y los colores detectados con bastante precisi√≥n.

Las m√°scaras fueron muy importantes porque ayudaron a concentrar la detecci√≥n solo en la mesa y a evitar confusiones con el fondo o las paredes. Gracias a esto, los resultados fueron mucho m√°s limpios y ordenados. En general, el programa funcion√≥ bien, ya que pudo diferenciar los colores sin problemas y mostrar claramente los objetos presentes en la escena.

**Conclusion**

En conclusi√≥n, el desarrollo de este taller permiti√≥ comprender de manera integral los fundamentos te√≥ricos y pr√°cticos del procesamiento digital de im√°genes aplicados a la calibraci√≥n de c√°maras y al an√°lisis visual. A trav√©s de las distintas actividades, desde la correcci√≥n de distorsiones √≥pticas hasta la segmentaci√≥n por color, se evidenci√≥ c√≥mo las transformaciones geom√©tricas, de intensidad y el manejo de histogramas contribuyen a mejorar la calidad, precisi√≥n y utilidad de la informaci√≥n visual. Adem√°s, la implementaci√≥n pr√°ctica con herramientas de \textit{OpenCV} y \textit{Python} facilit√≥ la conexi√≥n entre la teor√≠a y la aplicaci√≥n real, fortaleciendo la comprensi√≥n del flujo de trabajo en visi√≥n por computador. En conjunto, el taller consolid√≥ habilidades esenciales para futuras tareas de detecci√≥n, reconocimiento y an√°lisis autom√°tico de im√°genes en diversos entornos.

**Reporte de contribuci√≥n individual**

Los ejercicios fueron distribuidos en primera instancia de la siguiente forma:  
\> Punto 01: Realizado entre todos  
\> Punto 01: Reinaldo David Lopez Narvaez  
\> Punto 03: Santiago Betancur Montoya  
\> Punto 04: Monica Paola Vargas Tirado  
\> Punto 05: Jose Sebastian Garzon Parra

Posteriormente, nos fuimos reuniendo de forma peri√≥dica para revisar conjuntamente la soluci√≥n de los diferentes puntos.  
Luego, tomamos la decisi√≥n de crear un archivo .ipynb, de modo que cada integrante tuviera un espacio para escribir e implementar la forma en que pens√≥ y ejecut√≥ el ejercicio.  
En cuanto al informe, la estructura de carpetas y otros aspectos a desarrollar, su elaboraci√≥n fue un trabajo conjunto.

**Referencias bibliogr√°ficas**  
Soluci√≥n Ingenieril. (s. f.). \*Operaciones aritm√©ticas con im√°genes \- Visi√≥n artificial\*. \[https://solucioningenieril.com/vision\_artificial/operaciones\_aritmeticas\_con\_imagenes\](https://solucioningenieril.com/vision\_artificial/operaciones\_aritmeticas\_con\_imagenes)

L√≥pez, J. F. (2012, noviembre 2). \*Procesamiento digital de im√°genes\*. Blog de WordPress. \[[https://procesamientodigitalimagenes.wordpress.com/\](https://procesamientodigitalimagenes.wordpress.com/)](https://procesamientodigitalimagenes.wordpress.com/]\(https://procesamientodigitalimagenes.wordpress.com/\))

GeeksforGeeks. (2025, julio 15). Camera Calibration with Python ‚Äì OpenCV. https://www.geeksforgeeks.org/python/camera-calibration-with-python-opencv/

Sadekar, K., & Mallick, S. (2020, febrero 25). Camera Calibration using OpenCV. LearnOpenCV. https://learnopencv.com/camera-calibration-using-opencv/?authuser=1  
