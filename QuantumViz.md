---
title: "Taller 1: Fundamentos y calibraciÃ³n de cÃ¡mara"
description: "VisiÃ³n por Computador â€” Universidad Nacional de Colombia â€” Taller 1: calibraciÃ³n, transformaciones y segmentaciÃ³n."
layout: default
permalink: /
theme: minimal
---

<style>

/* Fuentes */
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700;800&display=swap');

:root{
Â  --bg:#f6f8fb;
Â  --card:#ffffff;
Â  --muted:#6b7280;
Â  --accent:#0f172a;
Â  --accent-2:#0ea5a4;
Â  --maxw:1200px;
}

/* Reset / body */
html,body{height:100%}
body{
Â  margin:0;
Â  padding:28px;
Â  font-family: 'Inter', system-ui, -apple-system, 'Segoe UI', Roboto, 'Helvetica Neue', Arial;
Â  background:linear-gradient(180deg,#fbfdff 0%, var(--bg) 100%);
Â  color:var(--accent);
Â  -webkit-font-smoothing:antialiased;
}

/* Layout */
.pro-wrapper{
Â  max-width: var(--maxw);
Â  margin: 0 auto;
Â  display: grid;
Â  grid-template-columns: 320px 1fr;
Â  gap: 28px;
Â  align-items: start;
Â  box-sizing: border-box;
Â  padding-bottom: 64px;
}

/* Sidebar */
#toc-sidebar{
Â  position: sticky;
Â  top: 28px;
Â  background: var(--card);
Â  border-radius: 12px;
Â  padding: 18px;
Â  box-shadow: 0 8px 24px rgba(11,15,30,0.06);
Â  border: 1px solid rgba(15,23,42,0.04);
Â  height: calc(100vh - 56px);
Â  overflow: auto;
}
#toc-sidebar h4{margin:0 0 10px 0;color:var(--accent-2);font-size:13px}
#toc-list{list-style:none;padding:0;margin:0}
#toc-list li{margin:8px 0;font-size:14px}
#toc-list li.h3{margin-left:10px;font-size:13px;color:var(--muted)}
#toc-list a{color:var(--accent);text-decoration:none}
#toc-list a:hover{text-decoration:underline}

/* Main content */
.pro-content{background:transparent;word-break:break-word}
.header-card{
Â  background:var(--card);
Â  padding:18px;
Â  border-radius:12px;
Â  box-shadow:0 8px 24px rgba(11,15,30,0.06);
Â  border:1px solid rgba(15,23,42,0.04);
Â  margin-bottom:18px;
}
.header-meta{display:flex;gap:20px;flex-wrap:wrap;color:var(--muted);font-size:14px}
.pro-content h1{font-size:28px;margin-top:4px;margin-bottom:8px}
.pro-content h2{font-size:20px;margin-top:28px;margin-bottom:8px}
.pro-content h3{font-size:16px;margin-top:18px;margin-bottom:6px}
.pro-content p{margin:8px 0;color:#10203a}
.pro-content ul{margin:6px 0 12px 20px}
.pro-content pre{background:#0b1220;color:#e6eef6;padding:12px;border-radius:8px;overflow:auto}

/* Section cards */
.section-card{
Â  background: var(--card);
Â  padding:20px;
Â  border-radius:12px;
Â  margin-bottom:18px;
Â  border: 1px solid rgba(15,23,42,0.04);
Â  box-shadow: 0 6px 18px rgba(11,15,30,0.03);
}

/* Floating actions */
.top-actions{
Â  position: fixed;
Â  right: 18px;
Â  bottom: 18px;
Â  display:flex;
Â  flex-direction:column;
Â  gap:10px;
Â  z-index:1200;
}
.btn{
Â  display:inline-flex;align-items:center;gap:8px;padding:10px 14px;background:var(--accent-2);color:white;border-radius:12px;border:none;box-shadow:0 8px 18px rgba(14,165,164,0.18);cursor:pointer;font-weight:700;text-decoration:none;font-size:14px;
}
.btn.secondary{background:#0f172a;padding:9px 12px}

.muted{color:var(--muted);font-size:13px}

/* Responsive */
@media (max-width:980px){
Â  .pro-wrapper{grid-template-columns:1fr;padding:0 12px}
Â  #toc-sidebar{position:relative;top:0;height:auto;margin-bottom:14px}
}

@media print{
Â  body{background:white;padding:0}
Â  #toc-sidebar{display:none}
Â  .pro-wrapper{grid-template-columns:1fr}
}

/* Smooth anchor scroll */
html { scroll-behavior: smooth; }
<style>

<!-- Layout HTML: sidebar + content wrapper -->
  
<div class="pro-wrapper">

Â  <aside id="toc-sidebar" aria-label="Tabla de contenido" role="navigation">
Â  Â  <h4>ğŸ“‘ Ãndice</h4>
Â  Â  <ul id="toc-list" aria-hidden="false"></ul>
Â  Â  <div style="height:12px"></div>
Â  Â  <div class="muted">VersiÃ³n profesional Â· Responsive Â· Imprimible</div>
Â  </aside>

Â  <main class="pro-content" id="pro-content">
  
<!-- START: contenido original -->

# Taller 1 â€” Fundamentos y calibraciÃ³n de cÃ¡mara

**VisiÃ³n por Computador**Â Â 
**Universidad Nacional de Colombia**Â Â 
**Docente:** Juan David Ospina Arango

**Estudiantes:**Â Â 
- Santiago Betancur MontoyaÂ Â 
- Reinaldo David Lopez NarvaezÂ Â 
- Jose Sebastian Garzon ParraÂ Â 
- Monica Paola Vargas Tirado

---

## ğŸ“‘ Tabla de contenido

1. [IntroducciÃ³n](#introducciÃ³n)Â Â 
2. [Marco teÃ³rico](#marco-teÃ³rico)Â Â 
Â  Â 1. [DistorsiÃ³n de lente (barril/cojÃ­n)](#distorsiÃ³n-de-lente-barrilcojÃ­n)Â Â 
Â  Â 2. [CalibraciÃ³n de cÃ¡mara](#calibraciÃ³n-de-cÃ¡mara)Â Â 
Â  Â 3. [Transformaciones geomÃ©tricas](#tranformciones-geometricas)Â Â 
Â  Â 4. [Transformaciones de intensidad a nivel de pÃ­xel](#transformaciones-de-intensidad-a-nivel-de-pixel)Â Â 
Â  Â 5. [EcualizaciÃ³n de histogramas](#ecualizaciÃ³n-de-histogramas)Â Â 
Â  Â 6. [SegmentaciÃ³n por color](#segmentaciÃ³n-por-color)Â Â 
3. [MetodologÃ­a](#metodologÃ­a)Â Â 
Â  Â 1. [CalibraciÃ³n de cÃ¡maras](#calibraciÃ³n-de-cÃ¡maras)Â Â 
Â  Â 2. [Transformaciones de intensidad a nivel de pÃ­xel](#transformaciones-de-intensidad-a-nivel-de-pixel-1)Â Â 
Â  Â 3. [Transformaciones de rotaciÃ³n y traslaciÃ³n](#transformaciones-de-rotaciÃ³n-y-traslaciÃ³n)Â Â 
Â  Â 4. [DistribuciÃ³n de intensidades de una imagen](#distribuciÃ³n-de-intensidades-de-una-imagen)Â Â 
Â  Â 5. [SegmentaciÃ³n de imÃ¡genes](#segmentaciÃ³n-de-imÃ¡genes)Â Â 
4. [Resultados y AnÃ¡lisis](#resultados-y-anÃ¡lisis)Â Â 
5. [ConclusiÃ³n](#conclusion)Â Â 
6. [Reporte de contribuciÃ³n individual](#reporte-de-contribuciÃ³n-individual)Â Â 
7. [Referencias bibliogrÃ¡ficas](#referencias-bibliogrÃ¡ficas)

---

## IntroducciÃ³n

El procesamiento digital de imÃ¡genes constituye uno de los pilares fundamentales de la visiÃ³n por computador, al permitir la interpretaciÃ³n automÃ¡tica de informaciÃ³n visual mediante algoritmos matemÃ¡ticos. En este primer taller se exploran los conceptos esenciales de calibraciÃ³n de cÃ¡mara, transformaciones de intensidad y geomÃ©tricas, ecualizaciÃ³n de histogramas y segmentaciÃ³n por color, con el propÃ³sito de comprender y manipular digitalmente la informaciÃ³n contenida en las imÃ¡genes.

El ejercicio se desarrolla de manera prÃ¡ctica utilizando fotografÃ­as capturadas con un telÃ©fono celular, lo que permite simular un entorno real de adquisiciÃ³n de datos. A partir de dichas imÃ¡genes, se aplican tÃ©cnicas bÃ¡sicas de preprocesamiento y anÃ¡lisis que permiten corregir distorsiones Ã³pticas, modificar el brillo, contraste y niveles de iluminaciÃ³n, realizar transformaciones espaciales, mejorar la distribuciÃ³n tonal mediante ecualizaciÃ³n y finalmente segmentar regiones de interÃ©s con base en sus caracterÃ­sticas cromÃ¡ticas.

Estas actividades permiten no solo afianzar los fundamentos teÃ³ricos del procesamiento de imÃ¡genes, sino tambiÃ©n evidenciar cÃ³mo cada operaciÃ³n afecta la percepciÃ³n visual y la informaciÃ³n contenida en los pÃ­xeles. De esta forma, el taller integra conceptos de geometrÃ­a, estadÃ­stica e interpretaciÃ³n visual para construir una comprensiÃ³n sÃ³lida del flujo de trabajo que precede a tareas mÃ¡s avanzadas de visiÃ³n artificial, como la detecciÃ³n de objetos, clasificaciÃ³n o reconocimiento de patrones.

---

## Marco teÃ³rico

### DistorsiÃ³n de lente (barril/cojÃ­n)

La distorsiÃ³n de lente es una aberraciÃ³n Ã³ptica que provoca que las lÃ­neas rectas en una escena aparezcan curvadas en la imagen capturada. Este efecto se debe a la geometrÃ­a y a la forma en que la lente proyecta la luz sobre el sensor de la cÃ¡mara. Existen principalmente dos tipos de distorsiÃ³n: la distorsiÃ³n de barril, donde las lÃ­neas rectas se curvan hacia afuera desde el centro de la imagen, comÃºn en lentes gran angulares; y la distorsiÃ³n de cojÃ­n, donde las lÃ­neas se curvan hacia adentro, tÃ­pica en lentes teleobjetivos. MatemÃ¡ticamente, estas distorsiones pueden modelarse mediante funciones polinomiales que dependen de la distancia radial al centro Ã³ptico. Corregir este tipo de errores requiere aplicar una transformaciÃ³n inversa basada en los parÃ¡metros intrÃ­nsecos de la cÃ¡mara, lo cual permite obtener una imagen rectificada que se aproxima a la proyecciÃ³n ideal

### CalibraciÃ³n de cÃ¡mara

El proceso de calibraciÃ³n de cÃ¡mara se basa en estimar los parÃ¡metros intrÃ­nsecos (como la longitud focal, el centro Ã³ptico y los coeficientes de distorsiÃ³n radial y tangencial) y los parÃ¡metros extrÃ­nsecos (rotaciÃ³n y traslaciÃ³n del sistema de cÃ¡mara respecto al mundo) para establecer una relaciÃ³n precisa entre un punto 3D del mundo y su proyecciÃ³n 2D en la imagen capturada (Sadekar & Mallick, 2020).
Para obtener estos parÃ¡metros se capturan mÃºltiples vistas de un patrÃ³n calibrado (frecuentemente un tablero de ajedrez), se localizan sus esquinas en la imagen, se asocian con las coordenadas del mundo definidas y se aplica un algoritmo como OpenCV calibrateCamera() para calcular la matriz intrÃ­nseca, los coeficientes de distorsiÃ³n, y los vectores de rotaciÃ³n y traslaciÃ³n. Este procedimiento permite corregir distorsiones y mejorar mediciones basadas en imagen para aplicaciones como robÃ³tica, visiÃ³n por computador y automÃ³viles autÃ³nomos (GeeksforGeeks, 2025).

### Tranformciones Geometricas

Las transformaciones geomÃ©tricas sobre imÃ¡genes permiten modificar su posiciÃ³n, orientaciÃ³n o tamaÃ±o sin alterar su contenido visual (al trabajar sobre la intensidad de cada pixel). Para representar estas transformaciones de manera uniforme y eficiente, se emplean las coordenadas homogÃ©neas, que aÃ±aden una dimensiÃ³n extra al sistema de coordenadas tradicional. Esto facilita expresar traslaciones, rotaciones y escalados mediante una Ãºnica matriz homogÃ©nea, la cual combina todas estas operaciones en una misma formulaciÃ³n matemÃ¡tica. De esta forma, las transformaciones pueden aplicarse mediante multiplicaciones matriciales, simplificando el procesamiento y la composiciÃ³n de mÃºltiples cambios geomÃ©tricos sobre la imagen.

### Transformaciones de intensidad a nivel de pixel

El procesamiento digital de imÃ¡genes se fundamenta en la aplicaciÃ³n de transformaciones puntuales que modifican las propiedades visuales de una imagen a nivel de pÃ­xel. Entre las mÃ¡s comunes se encuentran el ajuste de brillo, que incrementa o reduce la luminosidad global al sumar o restar un valor constante; el ajuste de contraste, que amplÃ­a o comprime el rango tonal para acentuar o suavizar las diferencias entre zonas claras y oscuras; y la correcciÃ³n gamma, una operaciÃ³n no lineal que compensa las caracterÃ­sticas de visualizaciÃ³n de los dispositivos y la percepciÃ³n humana, equilibrando el brillo y el contraste de forma mÃ¡s natural. Estas transformaciones son esenciales para optimizar la visualizaciÃ³n y mejorar la calidad perceptual de las imÃ¡genes digitales (LÃ³pez, 2012).
Asimismo, el tratamiento de imÃ¡genes puede incluir operaciones aritmÃ©ticas como suma, resta, multiplicaciÃ³n y divisiÃ³n entre imÃ¡genes o con constantes. Estas permiten realizar tareas de realce, fusiÃ³n o comparaciÃ³n visual, destacando diferencias o atenuando regiones especÃ­ficas. Por ejemplo, la suma puede aumentar el brillo o combinar dos imÃ¡genes, la resta resalta variaciones entre ellas, la multiplicaciÃ³n se emplea para aplicar mÃ¡scaras o modificar la iluminaciÃ³n, y la divisiÃ³n sirve para detectar cambios o corregir irregularidades de luz. En conjunto, estas transformaciones constituyen la base del anÃ¡lisis y procesamiento visual en mÃºltiples aplicaciones de la visiÃ³n por computador y la ingenierÃ­a digital (SoluciÃ³n Ingenieril, s. f.).

### EcualizaciÃ³n de histogramas

La ecualizaciÃ³n de histograma es una tÃ©cnica de mejora del contraste que busca redistribuir los niveles de intensidad de una imagen para utilizar de manera mÃ¡s uniforme todo el rango dinÃ¡mico disponible.
Este proceso se basa en la funciÃ³n de distribuciÃ³n acumulada (CDF) del histograma original, que transforma los valores de intensidad r en nuevos valores s, dando como resultado una imagen con un contraste mÃ¡s equilibrado y una mejor diferenciaciÃ³n entre regiones claras y oscuras. Esta tÃ©cnica es especialmente Ãºtil en imÃ¡genes con iluminaciÃ³n desigual o bajo contraste, como fotografÃ­as nocturnas o subexpuestas, aunque puede incrementar el ruido en Ã¡reas uniformes.

### SegmentaciÃ³n por color

La segmentaciÃ³n de imÃ¡genes permite dividir una imagen en regiones que representan objetos o Ã¡reas de interÃ©s, facilitando su anÃ¡lisis. En este caso, se utiliza para reconocer objetos de distintos colores, contarlos y calcular su tamaÃ±o en pÃ­xeles.

Para lograrlo, se emplean los espacios de color HSV y LAB, que ayudan a distinguir mejor los tonos y la iluminaciÃ³n. Con el uso de mÃ¡scaras y operaciones morfolÃ³gicas, se aÃ­sla la zona de interÃ©s (como la mesa) y se eliminan ruidos del fondo. Finalmente, se obtienen los contornos y el Ã¡rea de cada objeto, permitiendo una identificaciÃ³n precisa y visualmente clara de los colores presentes en la escena.

---

## MetodologÃ­a

### CalibraciÃ³n de cÃ¡maras

Se imprime un patrÃ³n calibrado (por ejemplo un tablero de ajedrez) y se toman mÃºltiples imÃ¡genes desde distintas orientaciones y distancias para abarcar diversas perspectivas del patrÃ³n. Luego se detectan las esquinas del patrÃ³n en cada imagen y se asocian estos puntos 2D con sus coordenadas espaciales 3D conocidas, tras lo cual se aplica la funciÃ³n de calibraciÃ³n (OpenCV calibrateCamera()) para estimar los parÃ¡metros intrÃ­nsecos (matriz de cÃ¡mara) y de distorsiÃ³n, asÃ­ como los vectores de rotaciÃ³n y traslaciÃ³n, y finalmente se verifican los resultados undistorcionando nuevas imÃ¡genes y comprobando el error de reproyecciÃ³n.

### Transformaciones de intensidad a nivel de pixel

Se definieron diversas funciones para realizar transformaciones sobre las imÃ¡genes, entre ellas ajuste_brillo(), ajuste_contraste() y correcciÃ³n_gamma(), junto con funciones auxiliares destinadas al manejo y normalizaciÃ³n de las mismas. Posteriormente, se procediÃ³ a cargar las fotografÃ­as de la fachada tomadas a las 6:00 a.m. y a las 7:00 p.m., sobre las cuales se aplicaron las transformaciones mencionadas, con el propÃ³sito de analizar y visualizar los efectos de cada ajuste sobre la imagen original.

De manera complementaria, se implementaron funciones para realizar operaciones aritmÃ©ticas entre imÃ¡genes, tales como suma(), resta(), multiplicaciÃ³n() y divisiÃ³n(). Estas operaciones se aplican igualmente a las imÃ¡genes capturadas a las 6:00 a.m. y 7:00 p.m., con el fin de observar cÃ³mo dichas combinaciones matemÃ¡ticas afectan la composiciÃ³n visual y los valores de intensidad de los pÃ­xeles, permitiendo una comprensiÃ³n mÃ¡s profunda de los principios de procesamiento digital de imÃ¡genes.

### Transformaciones de rotaciÃ³n y traslaciÃ³n

Iniciamos con la creaciÃ³n de funciones que permiten construir matrices en coordenadas homogÃ©neas para las transformaciones de rotaciÃ³n, escalamiento y traslaciÃ³n, cada una definida segÃºn los parÃ¡metros especÃ­ficos que la determinan. Con estas funciones se desarrolla posteriormente una rutina que genera la matriz homogÃ©nea compuesta, la cual combina las transformaciones bÃ¡sicas en una Ãºnica representaciÃ³n matricial, facilitando su aplicaciÃ³n sobre imÃ¡genes digitales.

A partir de esta composiciÃ³n, se generan mÃºltiples matrices homogÃ©neas (por defecto, ocho) modificando los parÃ¡metros de rotaciÃ³n, escalamiento y traslaciÃ³n para cada una. Estas matrices se aplican a una imagen previamente cargada, obteniendo un conjunto de resultados que se almacenan como frames. Posteriormente, los frames se integran para formar un GIF que muestra la secuencia de transformaciones. Todas las operaciones se realizaron tomando como referencia el centro de la imagen, por lo que la aplicaciÃ³n de cada transformaciÃ³n depende directamente de sus dimensiones. AdemÃ¡s, se aplicÃ³ un padding a cada frame con el fin de evitar la apariciÃ³n de zonas negras alrededor de la imagen transformada.

### DistribuciÃ³n de intensidades de una imagen

Se cargaron dos imÃ¡genes de la misma fachada tomadas en diferentes condiciones de iluminaciÃ³n (6 AM y 7PM). Ambas fueron redimensionadas y convertidas a escala de grises para analizar Ãºnicamente la distribuciÃ³n de intensidades. Posteriormente, se aplicÃ³ la ecualizaciÃ³n de histograma utilizando la funciÃ³n cv.equalizeHist() de OpenCV, con el fin de redistribuir los niveles de brillo y mejorar el contraste.

Finalmente, se calcularon y graficaron los histogramas y funciones de distribuciÃ³n acumulada (CDF) antes y despuÃ©s del proceso para comparar los cambios en la representaciÃ³n tonal entre la imagen diurna y la nocturna.

### SegmentaciÃ³n de imÃ¡genes

Para esta actividad, nuestro grupo capturÃ³ una imagen en una oficina con varios objetos de diferentes colores sobre una mesa, usando la cÃ¡mara de un telÃ©fono celular. Empleando las librerÃ­as OpenCV y NumPy para el manejo de imÃ¡genes y operaciones numÃ©ricas. La imagen fue cargada, redimensionada y convertida a los espacios de color HSV y LAB, lo que permitiÃ³ trabajar con informaciÃ³n de tono, saturaciÃ³n y luminosidad de forma mÃ¡s precisa que en el formato RGB.

El paso mÃ¡s importante fue la creaciÃ³n de mÃ¡scaras, utilizadas para aislar la superficie de la mesa y excluir el fondo o las paredes. Estas mÃ¡scaras se generaron mediante condiciones de brillo y saturaciÃ³n, y luego se limpiaron con operaciones morfolÃ³gicas de apertura y cierre para eliminar el ruido. La mÃ¡scara final definiÃ³ la regiÃ³n de interÃ©s, sobre la cual se realizÃ³ toda la segmentaciÃ³n por color, evitando errores en zonas no relevantes.

Finalmente, se aplicaron rangos de color en el espacio HSV para detectar objetos azules, verdes, rojos, naranjas, blancos y grises. Con las mÃ¡scaras de cada color se identificaron los contornos de los objetos, se filtraron por Ã¡rea mÃ­nima y se calculÃ³ su tamaÃ±o en pÃ­xeles. Los resultados se visualizaron en una imagen anotada que muestra los objetos detectados y sus Ã¡reas, comprobando la efectividad del uso de las mÃ¡scaras y las librerÃ­as empleadas para la segmentaciÃ³n.

---

## Resultados y AnÃ¡lisis

### CalibraciÃ³n de cÃ¡maras

Los resultados obtenidos del proceso de calibraciÃ³n muestran una buena consistencia en los parÃ¡metros intrÃ­nsecos y una representaciÃ³n fiel del comportamiento Ã³ptico de la cÃ¡mara. Se determinÃ³ que la distorsiÃ³n predominante es de tipo barril, lo cual se evidencia tanto en los valores positivos de los coeficientes radiales ğ‘˜_2 y ğ‘˜_3, como en la curvatura convexa de las lÃ­neas rectas hacia los bordes de las imÃ¡genes originales. Los valores de las longitudes focales ğ‘“_ğ‘¥ = 280.4 y ğ‘“_ğ‘¦ = 281.6 resultaron muy similares, indicando una correcta proporciÃ³n entre los ejes del sensor y una calibraciÃ³n precisa, sin deformaciones anisÃ³tropas significativas. Asimismo, el punto principal (ğ‘_ğ‘¥, ğ‘_ğ‘¦) = (183.67, 164.88) se encuentra prÃ³ximo al centro de la imagen, lo que confirma una adecuada alineaciÃ³n entre el eje Ã³ptico y el sensor. En conjunto, estos resultados reflejan una calibraciÃ³n estable y coherente, reforzada por un bajo error RMS de reproyecciÃ³n (â‰ˆ 0.27), que garantiza una correspondencia precisa entre los puntos proyectados y observados. La correcciÃ³n aplicada eliminÃ³ eficazmente la distorsiÃ³n radial, obteniendo imÃ¡genes rectificadas con lÃ­neas bien alineadas, lo cual valida la calidad del modelo de cÃ¡mara empleado.

### Transformaciones de intensidad a nivel de pixel

La aplicaciÃ³n de transformaciones de intensidad a nivel de pÃ­xel permitiÃ³ modificar de forma controlada las caracterÃ­sticas visuales de las imÃ¡genes segÃºn las condiciones de iluminaciÃ³n. En la imagen diurna, los ajustes de brillo y contraste evidenciaron que el aumento del brillo realza las zonas claras pero puede provocar pÃ©rdida de detalle por saturaciÃ³n, mientras que un incremento del contraste mejora la definiciÃ³n de bordes y sombras al ampliar el rango tonal. Por su parte, la correcciÃ³n gamma (Î³ < 1) permitiÃ³ iluminar de manera mÃ¡s uniforme sin saturar los valores altos de intensidad, siendo especialmente Ãºtil para compensar condiciones de baja iluminaciÃ³n.

En la imagen nocturna, los mismos ajustes contribuyeron a resaltar detalles ocultos en las sombras, aunque un incremento excesivo del brillo introdujo cierto ruido visual. Las operaciones aritmÃ©ticas entre imÃ¡genes (A y B) mostraron diferentes comportamientos: la suma (A + B) generÃ³ una fusiÃ³n mÃ¡s brillante que combina informaciÃ³n de ambas tomas; la resta (|A âˆ’ B|) resaltÃ³ las diferencias de iluminaciÃ³n y color entre el dÃ­a y la noche; la multiplicaciÃ³n (A Ã— B) oscureciÃ³ la escena, siendo Ãºtil para analizar regiones comunes; y la divisiÃ³n (A Ã· B) amplificÃ³ las diferencias de luminancia, destacando las estructuras mÃ¡s iluminadas. En conjunto, estos resultados demuestran que las transformaciones de intensidad son herramientas fundamentales en visiÃ³n por computador, al mejorar la percepciÃ³n visual, realizar correcciones fotomÃ©tricas y facilitar la segmentaciÃ³n o detecciÃ³n de caracterÃ­sticas bajo condiciones de iluminaciÃ³n variables.

### Transformaciones de rotaciÃ³n y traslaciÃ³n

Al implementar y aplicar las transformaciones de rotaciÃ³n y traslaciÃ³n, se obtuvieron resultados visuales claros del efecto progresivo de cada operaciÃ³n. El cÃ³digo desarrollado permitiÃ³ cargar una imagen base y generar entre ocho y doce transformaciones sucesivas, variando los parÃ¡metros de rotaciÃ³n, traslaciÃ³n y escala en cada paso. Cada resultado intermedio se almacenÃ³ como un frame, evidenciando los cambios graduales en la posiciÃ³n y orientaciÃ³n de la imagen. Finalmente, la secuencia completa de frames se integrÃ³ en un GIF animado que muestra de manera continua y dinÃ¡mica el proceso de transformaciÃ³n. Este resultado permite observar cÃ³mo la composiciÃ³n de transformaciones homogÃ©neas produce efectos coherentes y visualmente fluidos sobre la imagen original.

AdemÃ¡s, para evitar la apariciÃ³n de zonas negras en los bordes de la imagen durante las transformaciones, se implementÃ³ un mÃ©todo de padding basado en el reflejo de los pÃ­xeles del borde. Esta tÃ©cnica permitiÃ³ extender el contenido de la imagen hacia las Ã¡reas que quedaban vacÃ­as tras las rotaciones o traslaciones, logrando que cada frame mantuviera una apariencia uniforme y continua. Gracias a este procedimiento, el GIF final presenta una transiciÃ³n mÃ¡s limpia y sin interrupciones visuales en los lÃ­mites de la imagen.

### DistribuciÃ³n de intensidades de una imagen

Tras aplicar la ecualizaciÃ³n del histograma, se observÃ³ un incremento notable en el contraste general de ambas imÃ¡genes, especialmente en la fotografÃ­a nocturna.
En la imagen diurna, la ecualizaciÃ³n generÃ³ cambios leves al redistribuir los valores de intensidad, ya que la iluminaciÃ³n original ya era uniforme. En contraste, la imagen nocturna presentÃ³ una ampliaciÃ³n significativa del rango dinÃ¡mico, evidenciada en el histograma, que pasÃ³ de estar concentrado en los niveles bajos a distribuirse de manera mÃ¡s homogÃ©nea en todo el espectro de intensidades.

El resultado visual confirma que la ecualizaciÃ³n mejora la visibilidad de detalles en escenas subexpuestas, permitiendo distinguir elementos que antes estaban ocultos por la baja iluminaciÃ³n. Sin embargo, tambiÃ©n se aprecia un aumento del ruido en algunas zonas oscuras debido al realce de las diferencias de intensidad.

En conjunto, el anÃ¡lisis demuestra que la ecualizaciÃ³n del histograma es especialmente efectiva para mejorar el contraste en condiciones de iluminaciÃ³n deficiente, aunque su efecto en imÃ¡genes bien expuestas es mÃ¡s limitado.

### SegmentaciÃ³n de imÃ¡genes

El programa logrÃ³ reconocer correctamente los objetos de distintos colores que aparecen en la imagen tomada en la oficina. En total se identificaron 15 objetos: 4 azules, 1 verde, 2 naranjas, 3 blancos, 3 grises y 2 rojos. A cada uno se le calculÃ³ su tamaÃ±o en pÃ­xeles, mostrando una buena relaciÃ³n con su tamaÃ±o real en la foto. En la imagen final se pueden ver los contornos bien marcados y los colores detectados con bastante precisiÃ³n.

Las mÃ¡scaras fueron muy importantes porque ayudaron a concentrar la detecciÃ³n solo en la mesa y a evitar confusiones con el fondo o las paredes. Gracias a esto, los resultados fueron mucho mÃ¡s limpios y ordenados. En general, el programa funcionÃ³ bien, ya que pudo diferenciar los colores sin problemas y mostrar claramente los objetos presentes en la escena.

---

## Conclusion

En conclusiÃ³n, el desarrollo de este taller permitiÃ³ comprender de manera integral los fundamentos teÃ³ricos y prÃ¡cticos del procesamiento digital de imÃ¡genes aplicados a la calibraciÃ³n de cÃ¡maras y al anÃ¡lisis visual. A travÃ©s de las distintas actividades, desde la correcciÃ³n de distorsiones Ã³pticas hasta la segmentaciÃ³n por color, se evidenciÃ³ cÃ³mo las transformaciones geomÃ©tricas, de intensidad y el manejo de histogramas contribuyen a mejorar la calidad, precisiÃ³n y utilidad de la informaciÃ³n visual. AdemÃ¡s, la implementaciÃ³n prÃ¡ctica con herramientas de *OpenCV* y *Python* facilitÃ³ la conexiÃ³n entre la teorÃ­a y la aplicaciÃ³n real, fortaleciendo la comprensiÃ³n del flujo de trabajo en visiÃ³n por computador. En conjunto, el taller consolidÃ³ habilidades esenciales para futuras tareas de detecciÃ³n, reconocimiento y anÃ¡lisis automÃ¡tico de imÃ¡genes en diversos entornos.

---

## Reporte de contribuciÃ³n individual

- Punto 01: Realizado entre todos
- Punto 01: Reinaldo David Lopez Narvaez
- Punto 03: Santiago Betancur Montoya
- Punto 04: Monica Paola Vargas Tirado
- Punto 05: Jose Sebastian Garzon Parra

Posteriormente, nos fuimos reuniendo de forma periÃ³dica para revisar conjuntamente la soluciÃ³n de los diferentes puntos.
Luego, tomamos la decisiÃ³n de crear un archivo .ipynb, de modo que cada integrante tuviera un espacio para escribir e implementar la forma en que pensÃ³ y ejecutÃ³ el ejercicio.
En cuanto al informe, la estructura de carpetas y otros aspectos a desarrollar, su elaboraciÃ³n fue un trabajo conjunto.

---

## Referencias bibliogrÃ¡ficas

- SoluciÃ³n Ingenieril. (s. f.). *Operaciones aritmÃ©ticas con imÃ¡genes - VisiÃ³n artificial*. [https://solucioningenieril.com/vision_artificial/operaciones_aritmÃ©ticas_con_imÃ¡genes](https://solucioningenieril.com/vision_artificial/operaciones_aritmÃ©ticas_con_imÃ¡genes)Â Â 
- LÃ³pez, J. F. (2012, noviembre 2). *Procesamiento digital de imÃ¡genes*. Blog de WordPress. [https://procesamientodigitalimagenes.wordpress.com/](https://procesamientodigitalimagenes.wordpress.com/)Â Â 
- GeeksforGeeks. (2025, julio 15). Camera Calibration with Python â€“ OpenCV. https://www.geeksforgeeks.org/python/camera-calibration-with-python-opencv/Â Â 
- Sadekar, K., & Mallick, S. (2020, febrero 25). Camera Calibration using OpenCV. https://learnopencv.com/camera-calibration-using-opencv/?authuser=1

<!-- END: contenido original -->

Â  </main>
</div>

<script>
/*
Â  Genera la TOC sidebar a partir de los headings h2/h3 que ya estarÃ¡n presentes
Â  en el HTML final. Esta versiÃ³n es segura dentro de Jekyll si se envuelve con raw.
*/
(function(){
Â  function slugify(s){
Â  Â  return String(s).toLowerCase().trim()
Â  Â  Â  .replace(/[^a-z0-9\\s-Ã¡Ã©Ã­Ã³ÃºÃ±Ã¼]/g,'')
Â  Â  Â  .replace(/\\s+/g,'-');
Â  }

Â  function buildTOC(){
Â  Â  var toc = document.getElementById('toc-list');
Â  Â  if(!toc) return;
Â  Â  // busca headings dentro del main
Â  Â  var container = document.getElementById('pro-content') || document;
Â  Â  var nodes = container.querySelectorAll('h2, h3');
Â  Â  toc.innerHTML = '';
Â  Â  nodes.forEach(function(h){
Â  Â  Â  if(!h.id) h.id = slugify(h.textContent);
Â  Â  Â  var li = document.createElement('li');
Â  Â  Â  li.className = h.tagName.toLowerCase();
Â  Â  Â  var a = document.createElement('a');
Â  Â  Â  a.href = '#'+h.id;
Â  Â  Â  a.textContent = h.textContent;
Â  Â  Â  li.appendChild(a);
Â  Â  Â  if(h.tagName.toLowerCase() === 'h3') li.classList.add('h3');
Â  Â  Â  toc.appendChild(li);
Â  Â  });
Â  }

Â  if (document.readyState === 'loading') {
Â  Â  document.addEventListener('DOMContentLoaded', buildTOC);
Â  } else {
Â  Â  buildTOC();
Â  }
})();
</script>

<!-- Accesos rÃ¡pidos -->
<div class="top-actions" aria-hidden="false">
Â  <a class="btn" href="#pro-content">ğŸ” Ir al contenido</a>
Â  <a class="btn secondary" href="#toc-sidebar">ğŸ“‘ Ãndice</a>
</div>

